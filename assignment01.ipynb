{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ì¸ê³µì§€ëŠ¥ì„ í•™ìŠµí•  ë•Œ ì•Œì•„ì•¼ í•  ì£¼ìš” ëª¨ë¸ê³¼ ê¸°ìˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¸ê³µì§€ëŠ¥ì€ ê°€ì¥ ë„“ì€ ê°œë…ìœ¼ë¡œ ì´ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²• ì¤‘ì— ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì´ ìˆë‹¤. ë˜í•œ, ì¸ê³µì‹ ê²½ë§ì˜ í•œ ì¢…ë¥˜ì¸ ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hackernoon.imgix.net/images/9ln3ztv.jpg\" height=\"300px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê³¼ê±°ì˜ ì „í†µì ì¸ í”„ë¡œê·¸ë˜ë°ì€ ë°ì´í„°ì™€ ê·œì¹™ì„ í†µí•´ ê¸°ê³„ë¡œë¶€í„° ê²°ê³¼ë¥¼ ì¶œë ¥í–ˆë‹¤ë©´, ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì™€ ì •ë‹µ ìŒì„ ê¸°ê³„ì— í•™ìŠµì‹œì¼œ ìŠ¤ìŠ¤ë¡œ ê·œì¹™ì„ ë°œê²¬í•˜ë„ë¡ í•˜ëŠ” ê¸°ìˆ ì´ë‹¤. ì´ë•Œ, ëª©í‘œëŠ” training dataë¥¼ ì™„ë²½í•˜ê²Œ í•™ìŠµí•˜ì—¬ ì¬í˜„í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ taskë¥¼ ì˜ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í†µê³„ì  ëª¨í˜•ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜ëŠ” í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "- ì§€ë„ í•™ìŠµ(Supervised Learning)\n",
    "  - Training dataì— labelì´ ìˆëŠ” ê²½ìš°\n",
    "  - ex) íšŒê·€ë¶„ì„, ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„, ì˜ì‚¬ê²°ì •ë‚˜ë¬´, ëœë¤í¬ë ˆìŠ¤íŠ¸, ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë“±\n",
    "- ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)\n",
    "  -  Training dataì— labelì´ ì—†ëŠ” ê²½ìš°\n",
    "  - ex) ì£¼ì„±ë¶„ ë¶„ì„, ê³„ì¸µ í´ëŸ¬ìŠ¤í„°ë§, K-í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ ë“±\n",
    "- ì¤€ì§€ë„ í•™ìŠµ(Semi-supervised Learning)\n",
    "  - ì¼ë¶€ training dataì— labelì´ ìˆëŠ” ê²½ìš°\n",
    "- ê°•í™”í•™ìŠµ(Reinforcement Learning)\n",
    "  - ê³ ì •ëœ ë°ì´í„°ì…‹ì´ ì•„ë‹Œ íŠ¹ì • í™˜ê²½ì´ ì£¼ì–´ì§„ ê²½ìš°\n",
    "  - í–‰ë™(Action)ì— ëŒ€í•œ ë³´ìƒ(Reward)ìœ¼ë¡œ í•™ìŠµì´ ì´ë£¨ì–´ì§„ë‹¤ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¸ì‹ ëŸ¬ë‹ì˜ ëª¨í˜• ë° ì£¼ìš” ê¸°ìˆ ì—ëŠ” ì‹œê³„ì—´ ë¶„ì„(ì¶”ì„¸ ë¶„ì„, ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡, ìë™ ë¬¸ì¥ ìƒì„± ë“±), OCR(ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸ ì¶”ì¶œ), ì´ë¯¸ì§€ ë¶„ë¥˜, ì¶”ì²œ, ì˜ìƒ ì²˜ë¦¬, ìì—°ì–´ ì²˜ë¦¬, ì±—ë´‡, ìŒì„± ì¸ì‹ ë“± ê·¸ ì¢…ë¥˜ê°€ ë‹¤ì–‘í•˜ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ë¨¸ì‹ ëŸ¬ë‹ì˜ ì§€ë„í•™ìŠµì˜ ëŒ€í‘œì ì¸ ëª¨ë¸ê³¼ ê¸°ìˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(ğ’™^1, ğ‘¦^1) , â€¦ , (ğ’™^ğ‘, ğ‘¦^ğ‘)$ì˜ ë ˆì´ë¸”ë§ ëœ ìƒ˜í”Œì´ ìˆì„ ë•Œ, ë§¤í•‘ í•¨ìˆ˜ $ğ‘”: ğ‘¿ â†’ ğ’€$ë¥¼ í•™ìŠµí•´ì„œ ìƒˆë¡œìš´ $ğ’™'$ê°€ ì£¼ì–´ì§ˆ ë•Œ ì í•©í•œ $ğ‘¦'$ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì¶œë ¥í•˜ëŠ” ê²ƒì„ ì§€ë„í•™ìŠµ(Supervised Learning)ì´ë¼ê³  í•œë‹¤. ì´ë•Œ, ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ output $y$ê°€ continuous ë˜ëŠ” discreteí•¨ì— ë”°ë¼ íšŒê·€(Regression)ì™€ ë¶„ë¥˜(Classification) í¬ê²Œ ë‘ê°€ì§€ ìœ í˜•ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/Regression_vs_Classification.jpg\" height=\"250px\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì§€ë„í•™ìŠµì˜ ëŒ€í‘œì ì¸ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "\n",
    "- ì„ í˜• íšŒê·€ë¶„ì„(Linear Regression): ì¢…ì† ë³€ìˆ˜ì™€ í•˜ë‚˜ ì´ìƒì˜ ë…ë¦½ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•˜ëŠ” ì„ í˜•ì‹ì„ ì°¾ëŠ” ëª¨ë¸ì´ë‹¤. ì´ë•Œ, ë…ë¦½ ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ í•˜ë‚˜ì¼ ë•Œë¥¼ ë‹¨ìˆœ ì„ í˜• íšŒê·€, ì—¬ëŸ¬ê°œì¸ ê²½ìš°ì— ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¼ê³  í•œë‹¤.\n",
    "\n",
    "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20231129130431/11111111.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„(Logistic Regression): ì„ í˜• íšŒê·€ë¶„ì„ì€ ì¶œë ¥ë³€ìˆ˜ê°€ ì—°ì†ì ì¸ ê°’ì—ë§Œ ê°€ëŠ¥í•œ ë°˜ë©´, ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì€ ë²”ì£¼í˜•ë„ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/publication/367007823/figure/fig1/AS:11431281112303217@1673379396543/Logistic-regression-of-binary-classification-353-Support-Vector-Machine-SVM.ppm\" height=\"240px\" width=\"300px\">\n",
    "\n",
    "- K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN, K-nearest Neighbors): ê¸°ë³¸ì ìœ¼ë¡œ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¥¼ í†µí•´ Kê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ ì¤‘ ê°€ì¥ ê°€ê¹Œì´ ìˆëŠ” í¬ì¸íŠ¸ì˜ ë¼ë²¨ì— ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸\n",
    "\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:505/0*2_qzcm2gSe9l67aI.png\" height=\"250px\" width=\"300px\">\n",
    "  \n",
    "- ê²°ì • íŠ¸ë¦¬(Decision Tree Classification): íŠ¹ì • ê¸°ì¤€ì— ë”°ë¼ ë°ì´í„°ë¥¼ êµ¬ë¶„í•´ì„œ ì¼ë ¨ì˜ ë¶„ë¥˜ ê·œì¹™ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "  <img src=\"https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- ëœë¤ í¬ë ˆìŠ¤íŠ¸(Random Forest Classification): ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ë¥¼ êµ¬ì„±í•˜ê³ , ê° ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ìˆ˜ê²° ë°©ì‹ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê²°ì •í•˜ëŠ” ëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1010/1*R3oJiyaQwyLUyLZL-scDpw.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (SVM, Support Vector Machine): ì„œí¬íŠ¸ ë²¡í„°(ê²½ê³„ì„ ) ê°„ì˜ ë„ˆë¹„ë¥¼ ìµœëŒ€í™”, ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ë©°, ê³ ì°¨ì› ë°ì´í„°ì…‹ì„ ë¶„ë¥˜í•˜ëŠ”ë° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.\n",
    "\n",
    "  <img src=\"https://3.bp.blogspot.com/-12I3KUZYAZU/WHI90_mZokI/AAAAAAAAFzg/qaaiCYvhwT41_rp0PEQjE7GFkPEtNrzkwCLcB/s1600-rw/SVM%2Bin%2BR.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ(Naive Bayes Classifier): Featureë¼ë¦¬ ì¡°ê±´ë¶€ ë…ë¦½ì´ë¼ëŠ” ê°€ì •í•˜ì— ë¶„ë¥˜ê°€ ì´ë£¨ì–´ì§€ë©°, ì„¤ëª…í•˜ê¸° ì‰½ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scikit-learn ë¶„ë¥˜ ë˜ëŠ” íšŒê·€ ì•Œê³ ë¦¬ì¦˜ ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  class  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# dataset -> dataframe\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names) # feature\n",
    "df['class'] = wine.target # target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
       "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
       "       'proanthocyanins', 'color_intensity', 'hue',\n",
       "       'od280/od315_of_diluted_wines', 'proline', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[wine.feature_names]\n",
    "y = df['class'] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Support Vector Machine\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_svm = clf_svm.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_svm)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_svm)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_lr = clf_lr.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_lr)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_lr)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 2 18  1]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.95      0.94        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_gnb = clf_gnb.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_gnb)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_gnb)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
