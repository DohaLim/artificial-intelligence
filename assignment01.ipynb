{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 인공지능을 학습할 때 알아야 할 주요 모델과 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공지능은 가장 넓은 개념으로 이를 구현하는 방법 중에 데이터를 기반으로 학습하는 머신러닝이 있다. 또한, 인공신경망의 한 종류인 딥러닝은 머신러닝의 방법 중 하나로 다음 그림과 같이 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hackernoon.imgix.net/images/9ln3ztv.jpg\" height=\"300px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과거의 전통적인 프로그래밍은 데이터와 규칙을 통해 기계로부터 결과를 출력했다면, 머신러닝은 데이터와 정답 쌍을 기계에 학습시켜 스스로 규칙을 발견하도록 하는 기술이다. 이때, 목표는 training data를 완벽하게 학습하여 재현하는 것이 아니라, 새로운 데이터에 대해 task를 잘 수행할 수 있도록 통계적 모형을 구축하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝의 종류는 크게 다음과 같이 구분할 수 있다.\n",
    "\n",
    "- 지도 학습(Supervised Learning)\n",
    "  - Training data에 label이 있는 경우\n",
    "  - ex) 회귀분석, 로지스틱 회귀분석, 의사결정나무, 랜덤포레스트, 서포트 벡터 머신 등\n",
    "- 비지도 학습(Unsupervised Learning)\n",
    "  -  Training data에 label이 없는 경우\n",
    "  - ex) 주성분 분석, 계층 클러스터링, K-평균 클러스터링 등\n",
    "- 준지도 학습(Semi-supervised Learning)\n",
    "  - 일부 training data에 label이 있는 경우\n",
    "- 강화학습(Reinforcement Learning)\n",
    "  - 고정된 데이터셋이 아닌 특정 환경이 주어진 경우\n",
    "  - 행동(Action)에 대한 보상(Reward)으로 학습이 이루어진다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝의 모형 및 주요 기술에는 시계열 분석(추세 분석, 미래 수요 예측, 자동 문장 생성 등), OCR(이미지 속 텍스트 추출), 이미지 분류, 추천, 영상 처리, 자연어 처리, 챗봇, 음성 인식 등 그 종류가 다양하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 머신러닝의 지도학습의 대표적인 모델과 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(𝒙^1, 𝑦^1) , … , (𝒙^𝑁, 𝑦^𝑁)$의 레이블링 된 샘플이 있을 때, 매핑 함수 $𝑔: 𝑿 → 𝒀$를 학습해서 새로운 $𝒙'$가 주어질 때 적합한 $𝑦'$를 예측하여 출력하는 것을 지도학습(Supervised Learning)이라고 한다. 이때, 지도학습 알고리즘의 output $y$가 continuous 또는 discrete함에 따라 회귀(Regression)와 분류(Classification) 크게 두가지 유형으로 구분할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/Regression_vs_Classification.jpg\" height=\"250px\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습의 대표적인 모델은 다음과 같다.\n",
    "\n",
    "- 선형 회귀분석(Linear Regression): 종속 변수와 하나 이상의 독립 변수 간의 관계를 설명하는 선형식을 찾는 모델이다. 이때, 독립 변수의 개수가 하나일 때를 단순 선형 회귀, 여러개인 경우에 다중 선형 회귀라고 한다.\n",
    "\n",
    "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20231129130431/11111111.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- 로지스틱 회귀분석(Logistic Regression): 선형 회귀분석은 출력변수가 연속적인 값에만 가능한 반면, 로지스틱 회귀분석은 범주형도 가능하다.\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/publication/367007823/figure/fig1/AS:11431281112303217@1673379396543/Logistic-regression-of-binary-classification-353-Support-Vector-Machine-SVM.ppm\" height=\"240px\" width=\"300px\">\n",
    "\n",
    "- K-최근접 이웃(KNN, K-nearest Neighbors): 기본적으로 유클리디안 거리를 통해 K개의 데이터 포인트 중 가장 가까이 있는 포인트의 라벨에 분류하는 모델\n",
    "\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:505/0*2_qzcm2gSe9l67aI.png\" height=\"250px\" width=\"300px\">\n",
    "  \n",
    "- 결정 트리(Decision Tree Classification): 특정 기준에 따라 데이터를 구분해서 일련의 분류 규칙을 수행하는 모델이다.\n",
    "\n",
    "  <img src=\"https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- 랜덤 포레스트(Random Forest Classification): 여러 개의 의사결정나무를 구성하고, 각 의사결정나무의 예측 결과를 다수결 방식으로 조합하여 최종 예측 결과를 결정하는 모델이다.\n",
    "\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1010/1*R3oJiyaQwyLUyLZL-scDpw.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- 서포트 벡터 머신(SVM, Support Vector Machine): 서포트 벡터(경계선) 간의 너비를 최대화, 오차를 최소화하는 것을 목표로 하며, 고차원 데이터셋을 분류하는데 좋은 성능을 보인다.\n",
    "\n",
    "  <img src=\"https://3.bp.blogspot.com/-12I3KUZYAZU/WHI90_mZokI/AAAAAAAAFzg/qaaiCYvhwT41_rp0PEQjE7GFkPEtNrzkwCLcB/s1600-rw/SVM%2Bin%2BR.png\" height=\"200px\" width=\"300px\">\n",
    "\n",
    "- 나이브 베이즈(Naive Bayes Classifier): Feature끼리 조건부 독립이라는 가정하에 분류가 이루어지며, 설명하기 쉽다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scikit-learn 분류 또는 회귀 알고리즘 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  class  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# dataset -> dataframe\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names) # feature\n",
    "df['class'] = wine.target # target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
       "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
       "       'proanthocyanins', 'color_intensity', 'hue',\n",
       "       'od280/od315_of_diluted_wines', 'proline', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[wine.feature_names]\n",
    "y = df['class'] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Support Vector Machine\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_svm = clf_svm.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_svm)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_svm)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_lr = clf_lr.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_lr)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_lr)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 2 18  1]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.95      0.94        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_gnb = clf_gnb.predict(X_te_std)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_gnb)\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_te, pred_gnb)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
